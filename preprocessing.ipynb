{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9e80e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a9e86f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = EfficientNetB0(\n",
    "    weights=\"imagenet\",\n",
    "    include_top=False,\n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "model = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "model.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfc9b928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path):\n",
    "    img = Image.open(path).convert(\"RGB\")\n",
    "    img = img.resize((224, 224))\n",
    "    img = np.array(img, dtype=np.float32)\n",
    "    img = preprocess_input(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee212db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIR = \"images/train\"\n",
    "OUT_DIR = \"images/embeddings\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "BATCH_SIZE = 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82261eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16110/16110 [15:28<00:00, 17.35it/s]\n"
     ]
    }
   ],
   "source": [
    "image_files = sorted(os.listdir(IMAGE_DIR))\n",
    "\n",
    "batch = []\n",
    "names = []\n",
    "\n",
    "for i, img_name in enumerate(tqdm(image_files)):\n",
    "    img_path = os.path.join(IMAGE_DIR, img_name)\n",
    "    batch.append(load_image(img_path))\n",
    "    names.append(img_name)\n",
    "\n",
    "    if len(batch) == BATCH_SIZE or i == len(image_files) - 1:\n",
    "        batch = np.array(batch)\n",
    "        embeddings = model.predict(batch, verbose=0)\n",
    "\n",
    "        for name, emb in zip(names, embeddings):\n",
    "            np.save(\n",
    "                os.path.join(OUT_DIR, name.replace(\".png\", \".npy\")),\n",
    "                emb\n",
    "            )\n",
    "\n",
    "        batch, names = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba30531",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "ids = []\n",
    "\n",
    "for file in sorted(os.listdir(OUT_DIR)):\n",
    "    X.append(np.load(os.path.join(OUT_DIR, file)))\n",
    "    ids.append(file.replace(\".npy\", \"\"))\n",
    "\n",
    "X = np.array(X)\n",
    "np.save(\"train_embeddings_using_efficientnetb0.npy\", X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffe0b7a",
   "metadata": {},
   "source": [
    "Lets do same for test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3f388e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIR = \"images/test\"\n",
    "OUT_DIR = \"images/embeddings_test\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "BATCH_SIZE = 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e19b853",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5396/5396 [04:13<00:00, 21.25it/s]\n"
     ]
    }
   ],
   "source": [
    "image_files = sorted(os.listdir(IMAGE_DIR))\n",
    "\n",
    "batch = []\n",
    "names = []\n",
    "\n",
    "for i, img_name in enumerate(tqdm(image_files)):\n",
    "    img_path = os.path.join(IMAGE_DIR, img_name)\n",
    "    batch.append(load_image(img_path))\n",
    "    names.append(img_name)\n",
    "\n",
    "    if len(batch) == BATCH_SIZE or i == len(image_files) - 1:\n",
    "        batch = np.array(batch)\n",
    "        embeddings = model.predict(batch, verbose=0)\n",
    "\n",
    "        for name, emb in zip(names, embeddings):\n",
    "            np.save(\n",
    "                os.path.join(OUT_DIR, name.replace(\".png\", \".npy\")),\n",
    "                emb\n",
    "            )\n",
    "\n",
    "        batch, names = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e7d786",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = []\n",
    "ids1 = []\n",
    "\n",
    "for file in sorted(os.listdir(OUT_DIR)):\n",
    "    X1.append(np.load(os.path.join(OUT_DIR, file)))\n",
    "    ids1.append(file.replace(\".npy\", \"\"))\n",
    "\n",
    "X1 = np.array(X1)\n",
    "np.save(\"test_embeddings_using_efficientnetb0.npy\", X1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769b4f4c",
   "metadata": {},
   "source": [
    "Lets combine the tabular data with these generated embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7044acb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data  = pd.read_csv(\"test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd02848d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings_dict(folder):\n",
    "    emb_dict = {}\n",
    "    for f in os.listdir(folder):\n",
    "        if f.endswith(\".npy\"):\n",
    "            key = f.replace(\".npy\", \"\")\n",
    "            emb_dict[key] = np.load(os.path.join(folder, f))\n",
    "    return emb_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6792f1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_emb = load_embeddings_dict(\"images/embeddings_train\")\n",
    "test_emb  = load_embeddings_dict(\"images/embeddings_test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0ed1067",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_embedding = np.mean(np.stack(list(train_emb.values())), axis=0)\n",
    "\n",
    "os.makedirs(\"data/processed\", exist_ok=True)\n",
    "np.save(\"data/processed/mean_embedding.npy\", mean_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99184d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['date'] = pd.to_datetime(train_data['date'])\n",
    "test_data[\"date\"] = pd.to_datetime(test_data[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd52f131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Year\n",
    "train_data['year'] = train_data['date'].dt.year\n",
    "test_data['year'] = test_data['date'].dt.year\n",
    "# Extracting Month\n",
    "train_data['month'] = train_data['date'].dt.month\n",
    "test_data['month'] = test_data['date'].dt.month\n",
    "\n",
    "# Extracting Day\n",
    "train_data['day'] = train_data['date'].dt.day\n",
    "test_data['day'] = test_data['date'].dt.day\n",
    "\n",
    "# You can even extract the day of the week (0=Monday, 6=Sunday)\n",
    "train_data['day_of_week'] = train_data['date'].dt.dayofweek\n",
    "test_data['day_of_week'] = test_data['date'].dt.dayofweek\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87a7ae91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'date',\n",
       " 'price',\n",
       " 'bedrooms',\n",
       " 'bathrooms',\n",
       " 'sqft_living',\n",
       " 'sqft_lot',\n",
       " 'floors',\n",
       " 'waterfront',\n",
       " 'view',\n",
       " 'condition',\n",
       " 'grade',\n",
       " 'sqft_above',\n",
       " 'sqft_basement',\n",
       " 'yr_built',\n",
       " 'yr_renovated',\n",
       " 'zipcode',\n",
       " 'lat',\n",
       " 'long',\n",
       " 'sqft_living15',\n",
       " 'sqft_lot15',\n",
       " 'year',\n",
       " 'month',\n",
       " 'day',\n",
       " 'day_of_week']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabular_cols = list(train_data.columns)\n",
    "tabular_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f43c226",
   "metadata": {},
   "outputs": [],
   "source": [
    "del tabular_cols[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87c45d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tabular_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5c2a4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for _, row in train_data.iterrows():\n",
    "    rid = str(row[\"id\"])\n",
    "    \n",
    "    if rid not in train_emb:\n",
    "        continue  # drop row\n",
    "\n",
    "    tab = row[tabular_cols].values.astype(\"float32\")\n",
    "    img = train_emb[rid]\n",
    "\n",
    "    X_train.append(np.concatenate([tab, img]))\n",
    "    y_train.append(row[\"price\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ebd7b3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train, dtype=\"float32\")\n",
    "y_train = np.array(y_train, dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "11418d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "test_ids = []\n",
    "\n",
    "for _, row in test_data.iterrows():\n",
    "    rid = str(row[\"id\"])\n",
    "\n",
    "    tab = row[tabular_cols].values.astype(\"float32\")\n",
    "\n",
    "    if rid in test_emb:\n",
    "        img = test_emb[rid]\n",
    "    else:\n",
    "        img = mean_embedding\n",
    "\n",
    "    X_test.append(np.concatenate([tab, img]))\n",
    "    test_ids.append(rid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d7eed5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(X_test, dtype=\"float32\")\n",
    "test_ids = np.array(test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ebd3c78d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16209, 1302)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5e9a1c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"data/processed/X_train.npy\", X_train)\n",
    "np.save(\"data/processed/y_train.npy\", y_train)\n",
    "\n",
    "np.save(\"data/processed/X_test.npy\", X_test)\n",
    "np.save(\"data/processed/test_ids.npy\", test_ids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
